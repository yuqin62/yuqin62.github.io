<!DOCTYPE html>
<html>
<head>
    <!--<title>Project 4</title>-->
    <style>
        body {
            padding: 30px;
            width: 1000px;
            margin: auto;
            text-align: left;
            font-weight: 300;
            font-family: Arial, sans-serif;
        }
        h1, h2, h3 {
          font-family: 'Source Sans Pro', sans-serif;
        }
        h3 {
            font-size: 18px;
            font-weight: bold;
        }
        p {
            font-family: 'Source Sans Pro', sans-serif;
            text-align: center;
            font-size: 15px;
        }
        .center {
            text-align: center;
        }
        .image-row, .iframe-row {
            display: flex;
            justify-content: center;
            align-items: center;
        }
        .iframe-row iframe {
            margin: 10px;
        }
        .image-small {
            margin: 20px;
            width: 150px;
            height: auto;
        }
        .image-medium {
            margin: 5px;
            width: 240px;
            height: auto;
        }
        .image-medium-3 {
        margin: 5px;
        width: 240px;
        height: auto;
        }
        .image-medium-4 {
        margin: 3px;
        width: 165px;
        height: auto;
        }
        .image-medium-5 {
        margin: 1.5px;
        width: 130px;
        height: auto;
        }
        .image-medium-7 {
        margin: 1px;
        width: 100px;
        height: auto;
        }
        .image-large {
            margin: 10px;
            width: 600px;
            height: auto;
        }
        figcaption {
            font-family: 'Source Sans Pro', sans-serif;
            font-size: 12px;
            font-weight: normal;
            text-align: center;
            margin-top: 5px;
        }    
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <h1 align="middle">Project 5: Fun With Diffusion Models</h1>
    <br>
    <h2 align="middle">Yuqin Jiao</h2>
    <h2 align="middle">Part A: The Power of Diffusion Models</h2>
    <h2 align="middle">Overview for Part A</h2>
    <p>
        Part A is for taking pictures, selecting corresponding points from the two images, then compute homography, warping im1 to im2, 
        blending the two images into a mosaic.
    </p>
    <h2 align="middle">Part 0: Setup</h2>
    <p>
        For part 1, I set seed = 180, and used 3 prompts sampling from both stage 1 and stage 2. I also used num_inference_steps as 5 and 20.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-5" src="media/51.png" alt="Description of figure1_1">
            <figcaption>[num_inference_steps as 5] stage 1 output: an oil painting of a snowy mountain village</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/52.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 5] stage 1 output: a man wearing a hat</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/53.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 5] stage 1 output: a rocket ship</figcaption>
        </figure>
    </div>
    <br>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/54.png" alt="Description of figure1_1">
            <figcaption>[num_inference_steps as 5] stage 2 output: an oil painting of a snowy mountain village</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/55.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 5] stage 2 output: a man wearing a hat</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/56.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 5] stage 2 output: a rocket ship</figcaption>
        </figure>
    </div>
    <br>
    <div class="image-row">
        <figure>
            <img class="image-medium-5" src="media/201.png" alt="Description of figure1_1">
            <figcaption>[num_inference_steps as 20] stage 1 output: an oil painting of a snowy mountain village</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/202.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 20] stage 1 output: a man wearing a hat</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/203.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 20] stage 1 output: a rocket ship</figcaption>
        </figure>
    </div>
    <br>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/204.png" alt="Description of figure1_1">
            <figcaption>[num_inference_steps as 20] stage 2 output: an oil painting of a snowy mountain village</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/205.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 20] stage 2 output: a man wearing a hat</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/206.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 20] stage 2 output: a rocket ship</figcaption>
        </figure>
    </div>
    <br>

    <h2 align="middle">Part 1: Sampling Loops</h2>
    <p>
        In part 1, I wrote my own "sampling loops" that use the pretrained DeepFloyd denoisers.
    </p>
    <h2 align="middle">Part 1.1: Implementing the Forward Process</h2>
    <p>
        I implemented the noisy_im = forward(im, t) function, and also noised the test image at noise level [250, 500, 750]. 
        I used torch.randn_like() function to compute the noisy image, which is epsilon.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-4" src="media/Berkeley Campanile.png" alt="Description of figure1_1">
            <figcaption>[test image] Berkeley Campanile</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=250.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=250</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=500.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=500</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=750.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=750</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 1.2: Classical Denoising</h2>
    <p>
        I used Gaussian blur filtering to try to remove the noise. I used torchvision.transforms.functional.gaussian_blur to get the Gaussian-denoised version 
        images for the noisy test images correspondingly.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=250.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=250</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=500.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=500</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=750.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=750</figcaption>
        </figure>
    </div>
    <div class="image-row">
        <figure>
            <img class="image-medium-4" src="media/Gaussian Blur Denoising at t=250.png" alt="Description of figure1_1">
            <figcaption>[Classical Denoising] Gaussian Blur Denoising at t=250</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Gaussian Blur Denoising at t=500.png" alt="Description of figure1_2">
            <figcaption>[Classical Denoising] Gaussian Blur Denoising at t=500</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Gaussian Blur Denoising at t=750.png" alt="Description of figure1_2">
            <figcaption>[Classical Denoising] Gaussian Blur Denoising at t=750</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 1.3: One-Step Denoising</h2>
    <p>
        I used the pretrained diffusion model (stage_1.unet) to denoise. I used stage_1.unet to recover Gaussian noise from the image, 
        then remove the noise to recover the original image. The text prompt is set as "a high quality photo".
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=250.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=250</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=500.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=500</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=750.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=750</figcaption>
        </figure>
    </div>
    <div class="image-row">
        <figure>
            <img class="image-medium-4" src="media/Gaussian Blur Denoising at t=250.png" alt="Description of figure1_1">
            <figcaption>[One Step Denoising] Denoised estimate at t=250</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Gaussian Blur Denoising at t=500.png" alt="Description of figure1_2">
            <figcaption>[One Step Denoising] Denoised estimate at t=500</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Gaussian Blur Denoising at t=750.png" alt="Description of figure1_2">
            <figcaption>[One Step Denoising] Denoised estimate at t=750</figcaption>
        </figure>
    </div>
    
    <h2 align="middle">Part 1.4: Iterative Denoising</h2>
    <p>
        I implemented iterative denoising using the pretrained diffusion model (stage_1.unet). The process starts with a 
        highly noisy image at timestep t, and noise is progressively removed step by step using a custom schedule (strided_timesteps). 
        At each step, the model estimates the noise and reduces it, gradually recovering the original image. The text prompt is set as "a high quality photo." 
        To optimize the process, I skipped timesteps using a stride of 30, reducing computational cost while maintaining quality. The results were compared 
        to one-step denoising and Gaussian blur. Iterative denoising produced significantly cleaner images, demonstrating the model's ability to effectively handle high noise levels.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-5" src="media/noisy campanile t=90.png" alt="Description of figure1_1">
            <figcaption>Noisy Campanile at t=90</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/noisy campanile t=240.png" alt="Description of figure1_2">
            <figcaption>Noisy Campanile at t=240</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/noisy campanile t=390.png" alt="Description of figure1_2">
            <figcaption>Noisy Campanile at t=390</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/noisy campanile t=540.png" alt="Description of figure1_2">
            <figcaption>Noisy Campanile at t=540</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/noisy campanile t=690.png" alt="Description of figure1_2">
            <figcaption>Noisy Campanile at t=690</figcaption>
        </figure>
    </div>
    <div class="image-row">
        <figure>
            <img class="image-medium-4" src="media/Original.png" alt="Description of figure1_1">
            <figcaption>Original</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/iteratively denoised campanile.png" alt="Description of figure1_2">
            <figcaption>Iteratively Denoised Campanile</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/one-step denoised campanile.png" alt="Description of figure1_2">
            <figcaption>One-Step Denoised Campanile</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/gaussian blurred campanile.png" alt="Description of figure1_2">
            <figcaption>Gaussian Blurred Campanile</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 1.5: Diffusion Model Sampling</h2>
    <p>
        I used the pretrained diffusion model (stage_1.unet) to generate images from random noise. By setting i_start = 0 in the 
        iterative_denoise function, the model denoised pure noise step by step. Five images were generated using the text prompt 
        "a high quality photo" and displayed as results.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-5" src="media/sample 1.png" alt="Description of figure1_1">
            <figcaption>Sample 1</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/sample 2.png" alt="Description of figure1_2">
            <figcaption>Sample 2</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/sample 3.png" alt="Description of figure1_2">
            <figcaption>Sample 3</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/sample 4.png" alt="Description of figure1_2">
            <figcaption>Sample 4</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/sample 5.png" alt="Description of figure1_2">
            <figcaption>Sample 5</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 1.6: Classifier-Free Guidance (CFG)</h2>
    <p>
        I implemented Classifier-Free Guidance (CFG) using the diffusion model (stage_1.unet) to enhance image 
        quality by combining conditional and unconditional noise estimates. With a CFG scale of 7, I generated five 
        high-quality images from random noise, showcasing improved results compared to standard sampling techniques.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-5" src="media/sample 1 with cfg.png" alt="Description of figure1_1">
            <figcaption>Sample 1 with CFG</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/sample 2 with cfg.png" alt="Description of figure1_2">
            <figcaption>Sample 2 with CFG</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/sample 3 with cfg.png" alt="Description of figure1_2">
            <figcaption>Sample 3 with CFG</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/sample 4 with cfg.png" alt="Description of figure1_2">
            <figcaption>Sample 4 with CFG</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/sample 5 with cfg.png" alt="Description of figure1_2">
            <figcaption>Sample 5 with CFG</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 1.7: Image-to-image Translation</h2>
    <p>
        I implemented image-to-image translation using the pretrained diffusion model (stage_1.unet) and 
        Classifier-Free Guidance (CFG). Starting with a slightly noisy image, the model iteratively denoised 
        it to create "edits" that gradually resemble the original image. Using noise levels [1,3,5,7,10,20], 
        I generated edits with the prompt "a high-quality photo."
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-7" src="media/SDEdit00 i_start=1.png" alt="Description of figure1_1">
            <figcaption>SDEdit with i_start=1</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit00 i_start=3.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=3</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit00 i_start=5.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=5</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit00 i_start=7.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=7</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit00 i_start=10.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=10</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit00 i_start=20.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=20</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/test00.png" alt="Description of figure1_2">
            <figcaption>Campanile</figcaption>
        </figure>
    </div>

    <div class="image-row">
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=1.png" alt="Description of figure1_1">
            <figcaption>SDEdit with i_start=1</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=3.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=3</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=5.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=5</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=7.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=7</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=10.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=10</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=20.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=20</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/test01.png" alt="Description of figure1_2">
            <figcaption>Cube</figcaption>
        </figure>
    </div>

    <div class="image-row">
        <figure>
            <img class="image-medium-7" src="media/SDEdit02 i_start=1.png" alt="Description of figure1_1">
            <figcaption>SDEdit with i_start=1</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit02 i_start=3.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=3</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit02 i_start=5.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=5</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit02 i_start=7.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=7</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit02 i_start=10.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=10</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit02 i_start=20.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=20</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/test02.png" alt="Description of figure1_2">
            <figcaption>Playground</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 1.7.1: Editing Hand-Drawn and Web Images</h2>
    <p>
        I implemented image-to-image translation using the pretrained diffusion model (stage_1.unet) and 
        Classifier-Free Guidance (CFG). Starting with a slightly noisy image, the model iteratively denoised 
        it to create "edits" that gradually resemble the original image. Using noise levels [1,3,5,7,10,20], 
        I generated edits with the prompt "a high-quality photo."
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-7" src="media/scene00 i_start=1.png" alt="Description of figure1_1">
            <figcaption>[web image] Scene at i_start=1</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/scene00 i_start=3.png" alt="Description of figure1_2">
            <figcaption>[web image] Scene at i_start=3</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/scene00 i_start=5.png" alt="Description of figure1_2">
            <figcaption>[web image] Scene at i_start=5</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/scene00 i_start=7.png" alt="Description of figure1_2">
            <figcaption>[web image] Scene at i_start=7</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/scene00 i_start=10.png" alt="Description of figure1_2">
            <figcaption>[web image] Scene at i_start=10</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/scene00 i_start=20.png" alt="Description of figure1_2">
            <figcaption>[web image] Scene at i_start=20</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/scene00.png" alt="Description of figure1_2">
            <figcaption>[web image] Scene</figcaption>
        </figure>
    </div>

    <div class="image-row">
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=1.png" alt="Description of figure1_1">
            <figcaption>[drawn image] Pavilion at i_start=1</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=3.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Pavilion at i_start=3</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=5.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Pavilion at i_start=5</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=7.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Pavilion at i_start=7</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=10.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Pavilion at i_start=10</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=20.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Pavilion at i_start=20</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/draw00.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Pavilion</figcaption>
        </figure>
    </div>

    <div class="image-row">
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=1.png" alt="Description of figure1_1">
            <figcaption>[drawn image] Triangle at i_start=1</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=3.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Triangle at i_start=3</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=5.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Triangle at i_start=5</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=7.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Triangle at i_start=7</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=10.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Triangle at i_start=10</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=20.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Triangle at i_start=20</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/draw01.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Triangle</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part B: Feature Matching for Autostitching</h2>
    <h2 align="middle">Overview for Part B</h2>
    <p>
        Part B is for automatically detecting features, using algorithm to select corners(features), then blending the two images into a mosaic.
    </p>
    <h2 align="middle">Part 1: Detecting corner features in an image</h2>
    <p>
        For part 1, I used function get_harris_corners provided to find the corners on my original image, I set edge_discard=20.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/figure5_1.jpg" alt="Description of figure1_1">
            <figcaption>[figure5_1] original image</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/figure5_2.jpg" alt="Description of figure1_2">
            <figcaption>[figure5_2] corners on image with edge_discard=20</figcaption>
        </figure>
    </div>
    <br>    

    <h2 align="middle">Part 2: Extracting a Feature Descriptor for each feature point</h2>
    <p>
        For part 2, I used Adaptive Non-Maximal Suppression (ANMS) to reduce the number of corners,  ANMS selets corners based on the corner strength, to avoid having 
        many corners within a small scope, ANMS used a circle with radius to find the strengthest corner within the circle-neighborhood, if a neighboor corner has more
        strength than corner xi, then we choose corner xj. The general algorithm is 
        \[
        r_i = \min_{j} \| \vec{x}_i - \vec{x}_j \|, \quad \text{s.t.} \quad f(\vec{x}_i) &lt; c_{\text{robust}} f(\vec{x}_j), \quad \vec{x}_j \in \mathcal{I}
        \]
        for all corners, where \(\mathcal{I}\) is the set of detected corners.
        <br>
        After that, I blurred the whole image[figure6_2], and then sampled these patches from the larger 40x40 window to have a nice big blurred descriptor. Then I extracted 
        axis-aligned 8x8 patches for each corners as feature descriptor. I also used bias/gain-normalize to normalize the descriptors. 
        The figure6_3 shows the patches of three channles on the first corner after normalization.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/figure6_1.jpg" alt="Description of figure1_1">
            <figcaption>[figure6_1] top 500 corners after ANMS</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/figure6_2.jpg" alt="Description of figure1_2">
            <figcaption>[figure6_2] blurred whole original image</figcaption>
        </figure>
    </div>
    <br>
    <div class="image-row">
        <figure>
            <img class="image-large" src="media/figure6_3.jpg" alt="Description of figure1_1">
            <figcaption>[figure6_3] first set of patches with three channles</figcaption>
        </figure>
    </div>
    <br>

    <h2 align="middle">Part 3: Matching these feature descriptors between two images</h2>
    <p>
        To match the features on image01 and image02, I flattened the patch array as shape (# corners to get match, 64*3), and then I used dist2 to calculate the distance between 
        image01 descriptor and image02 descriptor. And I selected the 1NN and 2NN using the smallest distance values. Then I used Loweâ€™s trick, setting threshold = 0.4, to select 
        the most convincing matches on pairs of images.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-large" src="media/figure7_1.jpg" alt="Description of figure2_1">
            <figcaption>[figure7_1] matches on pair of images</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 4: Use a robust method (RANSAC) to compute a homography</h2>
    <p>
        Since the pairs of matches can not guarantee totally accurate, in this part, I used RANSAC to find the most accurate homography. Following the steps "# loop starts:
        # 1. Select four feature pairs (at random)
        # 2. Compute homography H (exact)
        # 3. Compute                  
        # loop ends
        # 4. Keep largest set of inliers
        # 5. Re-compute least-squares H estimate on all of the inliers", I found the homography on each pair of images, and then visulaized them.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/figure7_1.jpg" alt="Description of figure1_1">
            <figcaption>[figure7_1] matches on pair of images before RANSAC</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/figure7_2.jpg" alt="Description of figure1_2">
            <figcaption>[figure7_2] matches on pair of images after RANSAC</figcaption>
        </figure>
    </div>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/figure7_3.jpg" alt="Description of figure1_1">
            <figcaption>[figure7_3] matches on pair of images before RANSAC</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/figure7_4.jpg" alt="Description of figure1_2">
            <figcaption>[figure7_4] matches on pair of images after RANSAC</figcaption>
        </figure>
    </div>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/figure7_5.jpg" alt="Description of figure1_1">
            <figcaption>[figure7_5] matches on pair of images before RANSAC</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/figure7_6.jpg" alt="Description of figure1_2">
            <figcaption>[figure7_6] matches on pair of images after RANSAC</figcaption>
        </figure>
    </div>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/figure7_7.jpg" alt="Description of figure1_1">
            <figcaption>[figure7_7] matches on pair of images before RANSAC</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/figure7_8.jpg" alt="Description of figure1_2">
            <figcaption>[figure7_8] matches on pair of images after RANSAC</figcaption>
        </figure>
    </div>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/figure7_9.jpg" alt="Description of figure1_1">
            <figcaption>[figure7_9] matches on pair of images before RANSAC</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/figure7_10.jpg" alt="Description of figure1_2">
            <figcaption>[figure7_10] matches on pair of images after RANSAC</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 5: Proceed as in the first part to produce a mosaic</h2>
    <p>
        For part 1, I took 4 pair of pictures, with fixing the center of projection (COP) and rotating my camera while capturing photos. 
        Then I selected corresponding points on both images.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/figure3_1.jpg" alt="Description of figure1_1">
            <figcaption>[figure3_1] landscape around Moffitt (manual)</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/figure8_1.jpg" alt="Description of figure1_2">
            <figcaption>[figure8_1] landscape around Moffitt (automatically)</figcaption>
        </figure>
    </div>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/figure3_2.jpg" alt="Description of figure1_1">
            <figcaption>[figure3_2] interior of Wurster Hall (manual)</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/figure8_2.jpg" alt="Description of figure1_2">
            <figcaption>[figure8_2] interior of Wurster Hall (automatically)</figcaption>
        </figure>
    </div>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/figure3_3.jpg" alt="Description of figure1_1">
            <figcaption>[figure3_3] interior of Cory Hall (manual)</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/figure8_3.jpg" alt="Description of figure1_2">
            <figcaption>[figure8_3] interior of Cory Hall (automatically)</figcaption>
        </figure>
    </div>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/figure3_4.jpg" alt="Description of figure1_1">
            <figcaption>[figure3_4] stairs inside Wurster Hall (manual)</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/figure8_4.jpg" alt="Description of figure1_2">
            <figcaption>[figure8_4] stairs inside Wurster Hall (automatically)</figcaption>
        </figure>
    </div>

    <h2 align="middle">Reflection</h2>
    <p>
        In this project, I learned the algorithm of how to do automatical feature detecting, also I learned how to read a paper 
        and how to reproduce the algorithm from the paper.
    </p>


    <h2 align="middle">Bells and Whistles 1</h2>
    <p>
        For part 1 of Bells and Whistles: my own ideas, I took pictures from daytime and night from the same point, 
        then I mosaic these two images together.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/figure4_1.jpg" alt="Description of figure2_1">
            <figcaption>[figure4_1] image taken at night</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/figure4_2.jpg" alt="Description of figure2_2">
            <figcaption>[figure4_2] image taken at daytime</figcaption>
        </figure>
    </div>
    <div class="image-row">
        <figure>
            <img class="image-large" src="media/figure4_3.jpg" alt="Description of figure2_1">
            <figcaption>[figure4_3] mosaic image from night to daytime</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part B: Diffusion Models from Scratch</h2>
    <h2 align="middle">Overview for Part A</h2>
    <p>
        Part B is for implementing diffusion model and training on MNIST dataset.
    </p>

    <h2 align="middle">Bells and Whistles 1</h2>
    <p>
        For part 2 of Bells and Whistles: video mosaics, I made a mosaic video of a corrider in Wurster Hall. The first two videos are 
        the original videos, and the 3rd video is the mosaic video.
    </p>
    
</body>
</html>

