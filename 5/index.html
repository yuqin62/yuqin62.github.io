<!DOCTYPE html>
<html>
<head>
    <!--<title>Project 4</title>-->
    <style>
        body {
            padding: 30px;
            width: 1000px;
            margin: auto;
            text-align: left;
            font-weight: 300;
            font-family: Arial, sans-serif;
        }
        h1, h2, h3 {
          font-family: 'Source Sans Pro', sans-serif;
        }
        h3 {
            font-size: 18px;
            font-weight: bold;
        }
        p {
            font-family: 'Source Sans Pro', sans-serif;
            text-align: center;
            font-size: 15px;
        }
        .center {
            text-align: center;
        }
        .image-row, .iframe-row {
            display: flex;
            justify-content: center;
            align-items: center;
        }
        .iframe-row iframe {
            margin: 10px;
        }
        .image-small {
            margin: 20px;
            width: 150px;
            height: auto;
        }
        .image-medium {
            margin: 5px;
            width: 240px;
            height: auto;
        }
        .image-medium-3 {
        margin: 5px;
        width: 240px;
        height: auto;
        }
        .image-medium-4 {
        margin: 3px;
        width: 165px;
        height: auto;
        }
        .image-medium-5 {
        margin: 1.5px;
        width: 130px;
        height: auto;
        }
        .image-medium-7 {
        margin: 1px;
        width: 100px;
        height: auto;
        }
        .image-large {
            margin: 10px;
            width: 600px;
            height: auto;
        }
        figcaption {
            font-family: 'Source Sans Pro', sans-serif;
            font-size: 12px;
            font-weight: normal;
            text-align: center;
            margin-top: 5px;
        }    
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <h1 align="middle">Project 5: Fun With Diffusion Models</h1>
    <br>
    <h2 align="middle">Yuqin Jiao</h2>
    <h2 align="middle">Part A: The Power of Diffusion Models</h2>
    <h2 align="middle">Overview for Part A</h2>
    <p>
        Part A is for taking pictures, selecting corresponding points from the two images, then compute homography, warping im1 to im2, 
        blending the two images into a mosaic.
    </p>
    <h2 align="middle">Part 0: Setup</h2>
    <p>
        For part 1, I set seed = 180, and used 3 prompts sampling from both stage 1 and stage 2. I also used num_inference_steps as 5 and 20.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-5" src="media/51.png" alt="Description of figure1_1">
            <figcaption>[num_inference_steps as 5] stage 1 output: an oil painting of a snowy mountain village</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/52.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 5] stage 1 output: a man wearing a hat</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/53.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 5] stage 1 output: a rocket ship</figcaption>
        </figure>
    </div>
    <br>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/54.png" alt="Description of figure1_1">
            <figcaption>[num_inference_steps as 5] stage 2 output: an oil painting of a snowy mountain village</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/55.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 5] stage 2 output: a man wearing a hat</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/56.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 5] stage 2 output: a rocket ship</figcaption>
        </figure>
    </div>
    <br>
    <div class="image-row">
        <figure>
            <img class="image-medium-5" src="media/201.png" alt="Description of figure1_1">
            <figcaption>[num_inference_steps as 20] stage 1 output: an oil painting of a snowy mountain village</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/202.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 20] stage 1 output: a man wearing a hat</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/203.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 20] stage 1 output: a rocket ship</figcaption>
        </figure>
    </div>
    <br>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/204.png" alt="Description of figure1_1">
            <figcaption>[num_inference_steps as 20] stage 2 output: an oil painting of a snowy mountain village</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/205.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 20] stage 2 output: a man wearing a hat</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/206.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 20] stage 2 output: a rocket ship</figcaption>
        </figure>
    </div>
    <br>
    <div class="image-row">
        <figure>
            <img class="image-medium-5" src="media/401.png" alt="Description of figure1_1">
            <figcaption>[num_inference_steps as 40] stage 1 output: an oil painting of a snowy mountain village</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/402.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 40] stage 1 output: a man wearing a hat</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/403.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 40] stage 1 output: a rocket ship</figcaption>
        </figure>
    </div>
    <br>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/404.png" alt="Description of figure1_1">
            <figcaption>[num_inference_steps as 40] stage 2 output: an oil painting of a snowy mountain village</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/405.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 40] stage 2 output: a man wearing a hat</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/406.png" alt="Description of figure1_2">
            <figcaption>[num_inference_steps as 40] stage 2 output: a rocket ship</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 1: Sampling Loops</h2>
    <p>
        In part 1, I wrote my own "sampling loops" that use the pretrained DeepFloyd denoisers.
    </p>
    <h2 align="middle">Part 1.1: Implementing the Forward Process</h2>
    <p>
        I implemented the noisy_im = forward(im, t) function, and also noised the test image at noise level [250, 500, 750]. 
        I used torch.randn_like() function to compute the noisy image, which is epsilon.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-4" src="media/Berkeley Campanile.png" alt="Description of figure1_1">
            <figcaption>[test image] Berkeley Campanile</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=250.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=250</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=500.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=500</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=750.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=750</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 1.2: Classical Denoising</h2>
    <p>
        I used Gaussian blur filtering to try to remove the noise. I used torchvision.transforms.functional.gaussian_blur to get the Gaussian-denoised version 
        images for the noisy test images correspondingly.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=250.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=250</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=500.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=500</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=750.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=750</figcaption>
        </figure>
    </div>
    <div class="image-row">
        <figure>
            <img class="image-medium-4" src="media/Gaussian Blur Denoising at t=250.png" alt="Description of figure1_1">
            <figcaption>[Classical Denoising] Gaussian Blur Denoising at t=250</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Gaussian Blur Denoising at t=500.png" alt="Description of figure1_2">
            <figcaption>[Classical Denoising] Gaussian Blur Denoising at t=500</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Gaussian Blur Denoising at t=750.png" alt="Description of figure1_2">
            <figcaption>[Classical Denoising] Gaussian Blur Denoising at t=750</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 1.3: One-Step Denoising</h2>
    <p>
        I used the pretrained diffusion model (stage_1.unet) to denoise. I used stage_1.unet to recover Gaussian noise from the image, 
        then remove the noise to recover the original image. The text prompt is set as "a high quality photo".
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=250.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=250</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=500.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=500</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Noisy Campanile at t=750.png" alt="Description of figure1_2">
            <figcaption>[test image at noise level] Noisy Campanile at t=750</figcaption>
        </figure>
    </div>
    <div class="image-row">
        <figure>
            <img class="image-medium-4" src="media/Gaussian Blur Denoising at t=250.png" alt="Description of figure1_1">
            <figcaption>[One Step Denoising] Denoised estimate at t=250</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Gaussian Blur Denoising at t=500.png" alt="Description of figure1_2">
            <figcaption>[One Step Denoising] Denoised estimate at t=500</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/Gaussian Blur Denoising at t=750.png" alt="Description of figure1_2">
            <figcaption>[One Step Denoising] Denoised estimate at t=750</figcaption>
        </figure>
    </div>
    
    <h2 align="middle">Part 1.4: Iterative Denoising</h2>
    <p>
        I implemented iterative denoising using the pretrained diffusion model (stage_1.unet). The process starts with a 
        highly noisy image at timestep t, and noise is progressively removed step by step using a custom schedule (strided_timesteps). 
        At each step, the model estimates the noise and reduces it, gradually recovering the original image. The text prompt is set as "a high quality photo." 
        To optimize the process, I skipped timesteps using a stride of 30, reducing computational cost while maintaining quality. The results were compared 
        to one-step denoising and Gaussian blur. Iterative denoising produced significantly cleaner images, demonstrating the model's ability to effectively handle high noise levels.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-5" src="media/noisy campanile t=90.png" alt="Description of figure1_1">
            <figcaption>Noisy Campanile at t=90</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/noisy campanile t=240.png" alt="Description of figure1_2">
            <figcaption>Noisy Campanile at t=240</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/noisy campanile t=390.png" alt="Description of figure1_2">
            <figcaption>Noisy Campanile at t=390</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/noisy campanile t=540.png" alt="Description of figure1_2">
            <figcaption>Noisy Campanile at t=540</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/noisy campanile t=690.png" alt="Description of figure1_2">
            <figcaption>Noisy Campanile at t=690</figcaption>
        </figure>
    </div>
    <div class="image-row">
        <figure>
            <img class="image-medium-4" src="media/Original.png" alt="Description of figure1_1">
            <figcaption>Original</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/iteratively denoised campanile.png" alt="Description of figure1_2">
            <figcaption>Iteratively Denoised Campanile</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/one-step denoised campanile.png" alt="Description of figure1_2">
            <figcaption>One-Step Denoised Campanile</figcaption>
        </figure>
        <figure>
            <img class="image-medium-4" src="media/gaussian blurred campanile.png" alt="Description of figure1_2">
            <figcaption>Gaussian Blurred Campanile</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 1.5: Diffusion Model Sampling</h2>
    <p>
        I used the pretrained diffusion model (stage_1.unet) to generate images from random noise. By setting i_start = 0 in the 
        iterative_denoise function, the model denoised pure noise step by step. Five images were generated using the text prompt 
        "a high quality photo" and displayed as results.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-5" src="media/sample 1.png" alt="Description of figure1_1">
            <figcaption>Sample 1</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/sample 2.png" alt="Description of figure1_2">
            <figcaption>Sample 2</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/sample 3.png" alt="Description of figure1_2">
            <figcaption>Sample 3</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/sample 4.png" alt="Description of figure1_2">
            <figcaption>Sample 4</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/sample 5.png" alt="Description of figure1_2">
            <figcaption>Sample 5</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 1.6: Classifier-Free Guidance (CFG)</h2>
    <p>
        I implemented Classifier-Free Guidance (CFG) using the diffusion model (stage_1.unet) to enhance image 
        quality by combining conditional and unconditional noise estimates. With a CFG scale of 7, I generated five 
        high-quality images from random noise, showcasing improved results compared to standard sampling techniques.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-5" src="media/sample 1 with cfg.png" alt="Description of figure1_1">
            <figcaption>Sample 1 with CFG</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/sample 2 with cfg.png" alt="Description of figure1_2">
            <figcaption>Sample 2 with CFG</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/sample 3 with cfg.png" alt="Description of figure1_2">
            <figcaption>Sample 3 with CFG</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/sample 4 with cfg.png" alt="Description of figure1_2">
            <figcaption>Sample 4 with CFG</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/sample 5 with cfg.png" alt="Description of figure1_2">
            <figcaption>Sample 5 with CFG</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 1.7: Image-to-image Translation</h2>
    <p>
        I implemented image-to-image translation using the pretrained diffusion model (stage_1.unet) and 
        Classifier-Free Guidance (CFG). Starting with a slightly noisy image, the model iteratively denoised 
        it to create "edits" that gradually resemble the original image. Using noise levels [1,3,5,7,10,20], 
        I generated edits with the prompt "a high-quality photo."
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-7" src="media/SDEdit00 i_start=1.png" alt="Description of figure1_1">
            <figcaption>SDEdit with i_start=1</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit00 i_start=3.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=3</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit00 i_start=5.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=5</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit00 i_start=7.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=7</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit00 i_start=10.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=10</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit00 i_start=20.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=20</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/test00.png" alt="Description of figure1_2">
            <figcaption>Campanile</figcaption>
        </figure>
    </div>

    <div class="image-row">
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=1.png" alt="Description of figure1_1">
            <figcaption>SDEdit with i_start=1</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=3.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=3</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=5.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=5</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=7.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=7</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=10.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=10</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit01 i_start=20.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=20</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/test01.png" alt="Description of figure1_2">
            <figcaption>Cube</figcaption>
        </figure>
    </div>

    <div class="image-row">
        <figure>
            <img class="image-medium-7" src="media/SDEdit02 i_start=1.png" alt="Description of figure1_1">
            <figcaption>SDEdit with i_start=1</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit02 i_start=3.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=3</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit02 i_start=5.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=5</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit02 i_start=7.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=7</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit02 i_start=10.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=10</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/SDEdit02 i_start=20.png" alt="Description of figure1_2">
            <figcaption>SDEdit with i_start=20</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/test02.png" alt="Description of figure1_2">
            <figcaption>Playground</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 1.7.1: Editing Hand-Drawn and Web Images</h2>
    <p>
        I used the pretrained diffusion model (stage_1.unet) with Classifier-Free Guidance (CFG) to transform non-realistic 
        images, such as sketches and web images, into natural-looking images. Using the interaction tool provided, I edited 
        one web image and two hand-drawn images by applying iterative denoising at noise levels [1,3,5,7,10,20]. The results 
        demonstrate the model's ability to project creative edits onto the natural image manifold.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-7" src="media/scene00 i_start=1.png" alt="Description of figure1_1">
            <figcaption>[web image] Scene at i_start=1</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/scene00 i_start=3.png" alt="Description of figure1_2">
            <figcaption>[web image] Scene at i_start=3</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/scene00 i_start=5.png" alt="Description of figure1_2">
            <figcaption>[web image] Scene at i_start=5</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/scene00 i_start=7.png" alt="Description of figure1_2">
            <figcaption>[web image] Scene at i_start=7</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/scene00 i_start=10.png" alt="Description of figure1_2">
            <figcaption>[web image] Scene at i_start=10</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/scene00 i_start=20.png" alt="Description of figure1_2">
            <figcaption>[web image] Scene at i_start=20</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/scene00.png" alt="Description of figure1_2">
            <figcaption>[web image] Scene</figcaption>
        </figure>
    </div>

    <div class="image-row">
        <figure>
            <img class="image-medium-7" src="media/draw00 i_start=1.png" alt="Description of figure1_1">
            <figcaption>[drawn image] Pavilion at i_start=1</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/Sdraw00 i_start=3.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Pavilion at i_start=3</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/draw00 i_start=5.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Pavilion at i_start=5</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/draw00 i_start=7.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Pavilion at i_start=7</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/draw00 i_start=10.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Pavilion at i_start=10</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/draw00 i_start=20.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Pavilion at i_start=20</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/draw00.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Pavilion</figcaption>
        </figure>
    </div>

    <div class="image-row">
        <figure>
            <img class="image-medium-7" src="media/draw01 i_start=1.png" alt="Description of figure1_1">
            <figcaption>[drawn image] Triangle at i_start=1</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/draw01 i_start=3.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Triangle at i_start=3</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/draw01 i_start=5.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Triangle at i_start=5</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/draw01 i_start=7.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Triangle at i_start=7</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/draw01 i_start=10.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Triangle at i_start=10</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/draw01 i_start=20.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Triangle at i_start=20</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/draw01.png" alt="Description of figure1_2">
            <figcaption>[drawn image] Triangle</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 1.7.2: Inpainting</h2>
    <p>
        I implemented inpainting using the pretrained diffusion model (stage_1.unet) with Classifier-Free Guidance (CFG), 
        following the RePaint paper. Using a binary mask, I replaced parts of an image with new content while preserving the 
        unmasked regions. The process iteratively added noise and denoised the image while respecting the mask constraints. 
        The figures include the test image inpainted (with a given mask) and two additional images edited using corresponding masks.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-5" src="media/inpaint00.png" alt="Description of figure1_1">
            <figcaption>Campanile</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/mask00.png" alt="Description of figure1_2">
            <figcaption>Mask</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/hole to fill00.png" alt="Description of figure1_2">
            <figcaption>Hole to Fill</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/inpainted00.png" alt="Description of figure1_2">
            <figcaption>Campanile Inpainted</figcaption>
        </figure>
    </div>

    <div class="image-row">
        <figure>
            <img class="image-medium-5" src="media/inpaint01.png" alt="Description of figure1_1">
            <figcaption>Cube</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/mask01.png" alt="Description of figure1_2">
            <figcaption>Mask</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/hole to fill01.png" alt="Description of figure1_2">
            <figcaption>Hole to Fill</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/inpainted01.png" alt="Description of figure1_2">
            <figcaption>Cube Inpainted</figcaption>
        </figure>
    </div>

    <div class="image-row">
        <figure>
            <img class="image-medium-5" src="media/inpaint02.png" alt="Description of figure1_1">
            <figcaption>Playground</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/mask02.png" alt="Description of figure1_2">
            <figcaption>Mask</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/hole to fill02.png" alt="Description of figure1_2">
            <figcaption>Hole to Fill</figcaption>
        </figure>
        <figure>
            <img class="image-medium-5" src="media/inpainted02.png" alt="Description of figure1_2">
            <figcaption>Playground Inpainted</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 1.7.3: Text-Conditional Image-to-image Translation</h2>
    <p>
        I implemented text-conditional image-to-image translation using the pretrained diffusion model (stage_1.unet) with Classifier-Free 
        Guidance (CFG). By combining iterative denoising and text prompts, the model transforms noisy images to align with the text 
        description while retaining features of the original image. The process was applied at noise levels [1,3,5,7,10,20]. The figures with different prompts: 
        1. Rocket Ship: Using the prompt "a rocket ship," the test image was guided to incorporate rocket-like campanile. 2. Pencil: Using the 
        prompt "a pencil," the test image was translated to resemble a pencil-like cube. 3. Hipster Barista: Using the prompt "a photo of a 
        hipster barista," the test image was edited to blend features of the original playground with the text prompt.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-7" src="media/rocket ship at noise level 1.png" alt="Description of figure1_1">
            <figcaption>[rocket ship] rocket ship at noise level 1</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/rocket ship at noise level 3.png" alt="Description of figure1_2">
            <figcaption>[rocket ship] rocket ship at noise level 3</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/rocket ship at noise level 5.png" alt="Description of figure1_2">
            <figcaption>[rocket ship] rocket ship at noise level 5</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/rocket ship at noise level 7.png" alt="Description of figure1_2">
            <figcaption>[rocket ship] rocket ship at noise level 7</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/rocket ship at noise level 10.png" alt="Description of figure1_2">
            <figcaption>[rocket ship] rocket ship at noise level 10</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/rocket ship at noise level 20.png" alt="Description of figure1_2">
            <figcaption>[rocket ship] rocket ship at noise level 20</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/test00.png" alt="Description of figure1_2">
            <figcaption>[rocket ship] Campanile</figcaption>
        </figure>
    </div>

    <div class="image-row">
        <figure>
            <img class="image-medium-7" src="media/pencil at noise level 1.png" alt="Description of figure1_1">
            <figcaption>[pencil] pencil at noise level 1</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/pencil at noise level 3.png" alt="Description of figure1_2">
            <figcaption>[pencil] pencil at noise level 3</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/pencil at noise level 5.png" alt="Description of figure1_2">
            <figcaption>[pencil] pencil at noise level 5</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/pencil at noise level 7.png" alt="Description of figure1_2">
            <figcaption>[pencil] pencil at noise level 7</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/pencil at noise level 10.png" alt="Description of figure1_2">
            <figcaption>[pencil] pencil at noise level 10</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/pencil at noise level 20.png" alt="Description of figure1_2">
            <figcaption>[pencil] pencil at noise level 20</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/test00.png" alt="Description of figure1_2">
            <figcaption>[pencil] Cube</figcaption>
        </figure>
    </div>

    <div class="image-row">
        <figure>
            <img class="image-medium-7" src="media/barista at noise level 1.png" alt="Description of figure1_1">
            <figcaption>[rocket ship] barista at noise level 1</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/barista at noise level 3.png" alt="Description of figure1_2">
            <figcaption>[rocket ship] barista at noise level 3</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/barista at noise level 5.png" alt="Description of figure1_2">
            <figcaption>[rocket ship] barista at noise level 5</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/barista at noise level 7.png" alt="Description of figure1_2">
            <figcaption>[rocket ship] barista at noise level 7</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/barista at noise level 10.png" alt="Description of figure1_2">
            <figcaption>[rocket ship] barista at noise level 10</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/barista at noise level 20.png" alt="Description of figure1_2">
            <figcaption>[rocket ship] barista at noise level 20</figcaption>
        </figure>
        <figure>
            <img class="image-medium-7" src="media/test02.png" alt="Description of figure1_2">
            <figcaption>[rocket ship] Playground</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 1.8: Visual Anagrams</h2>
    <p>
        I implemented Visual Anagrams using the pretrained diffusion model (stage_1.unet) with Classifier-Free Guidance (CFG). 
        The first group of outputs combines two noise estimates guided by different prompts: "an oil painting of an old man" and "an oil painting of people around a campfire". 
        The second group of outputs combines two noise estimates guided by different prompts: "a photo of a hipster barista" and "an oil painting of an old man". 
        The third group of outputs combines two noise estimates guided by different prompts: "a pencil" and "a man wearing a hat". 
        By flipping the image and corresponding noise estimate, averaging the results, and denoising iteratively, the model generates an image that appears differently when flipped upside down.
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/people around a campfire1.png" alt="Description of figure1_1">
            <figcaption>[Prompt] An Oil Painting of an Old Man</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/people around a campfire2.png" alt="Description of figure1_2">
            <figcaption>[Prompt] An Oil Painting of People around a Campfire</figcaption>
        </figure>
    </div>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/hipster barista1.png" alt="Description of figure1_1">
            <figcaption>[Prompt] A Photo of A Hipster Barista</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/hipster barista2.png" alt="Description of figure1_2">
            <figcaption>[Prompt] An Oil Painting of an Old Man</figcaption>
        </figure>
    </div>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/a pencil1.png" alt="Description of figure1_1">
            <figcaption>[Prompt] A Pencil</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/a pencil2.png" alt="Description of figure1_2">
            <figcaption>[Prompt] A Man Wearing A Hat</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part 1.9: Hybrid Images</h2>
    <p>
        I implemented Hybrid Images using the pretrained diffusion model (stage_1.unet) with Classifier-Free Guidance (CFG). 
        By combining noise estimates from two prompts—"a lithograph of a skull" and "a lithograph of waterfalls"—the model 
        creates a composite noise estimate. Low frequencies from one noise estimate are blended with high frequencies from the 
        other using a Gaussian blur (kernel size 33, sigma 2). The final hybrid image appears as a skull from afar and transforms 
        into waterfalls when viewed up close. I also tried another two groups of prompts, which are "a pencil" with "a rocket ship" 
        and "an oil painting of people around a campfire" with "a photo of a dog".
    </p>
    <div class="image-row">
        <figure>
            <img class="image-medium-3" src="media/download (3).png" alt="Description of figure1_1">
            <figcaption>Hybrid image of a skull and a waterfall</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/download (2).png" alt="Description of figure1_2">
            <figcaption>Hybrid image of a rocket ship and a pencil</figcaption>
        </figure>
        <figure>
            <img class="image-medium-3" src="media/download (1).png" alt="Description of figure1_2">
            <figcaption>Hybrid image of an oil painting of people around a campfire and a dog</figcaption>
        </figure>
    </div>

    <h2 align="middle">Part B: Diffusion Models from Scratch</h2>
    <h2 align="middle">Overview for Part A</h2>
    <p>
        Part B is for implementing diffusion model and training on MNIST dataset.
    </p>

    <h2 align="middle">Reflection</h2>
    <p>
        In this project, I learned the algorithm of how to do automatical feature detecting, also I learned how to read a paper 
        and how to reproduce the algorithm from the paper.
    </p>

    <h2 align="middle">Bells and Whistles 1</h2>
    <p>
        For part 2 of Bells and Whistles: video mosaics, I made a mosaic video of a corrider in Wurster Hall. The first two videos are 
        the original videos, and the 3rd video is the mosaic video.
    </p>
    
</body>
</html>

